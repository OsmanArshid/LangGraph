{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, we covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_google_genai langgraph_sdk python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yea\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    # print(GOOGLE_API_KEY)\n",
    "    print(\"yea\")\n",
    "else:\n",
    "    print(\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAFNCAIAAAAxQhXgAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/BPyE6AsASRPUUFQUXqBsS9cK868Gu/WhVHq7XWLbWOitYKjjrqti6s0Cq1bkVxC4KCKBsEZJNJ5u+P85vys4AKOe5yeT8f/EHuLpf3JXnl7nPjczSNRoMAAEQzIroAAACCKAJAFhBFAEgBoggAKUAUASAFiCIApMAguoAWotFoSnJrxTVKiVClUmrkMjXRFX0Ym2tEZ9B4JnSeCb21M5focgC+KB5FjVrz4kFNdoo454XEoS2XyTLimdDNrVlIHw6majSotKBWIlRpNJrctEKXDnxXH75XV1Oi6wK4oFH4EP/jq5XPblc5efFdfPguHfhEl9MsapUm+7k4K0WcmyYOGGjRsbcZ0RUBHaNmFHPTxZcOl3j3MO0x3IroWnRMqVDfiSvPShENnmHb2olDdDlAZygYxSfXKotzZCGTrNlcOtG14EVUpYw/WNS+m2mH7gKiawG6QbUoJt+qElUpe46g2sqwXtdOvXXw5Hp0MiG6EKADlIrizbOlRgzUe2QrogtpOVdOlJiYMz4bbEl0IaC5qHNcMTWxWq3SGFQOEUL9JtuUF8kzn4mILgQ0F0WiWJwrLc6WBU+wJroQAgz5j+3LR8KqUjnRhYBmoUgUb/9e5t3DcHdgtPvMNOF8GdFVgGahQhSzUkQ8E0ZrZ8Pds+/SgV8rVb/JkhJdCGg6KkTx5SNhr1BD32/Ra6TVi3vVRFcBmk7vo1hRIq8olgusWEQXQjAbR07OC4lUpCK6ENBEeh/F7FSxi3dLn9R2+vTpNWvWNOGJ/fv3LywsxKEihBBy8eZnp4pxmjnAm95HsTRf5tbRuIVf9MWLF014VlFRUWVlJQ7lvOPuZ1yUA81FfaX3V2YUvJYGjsXrGEZOTs6ePXseP36s0Wg6duw4bdo0Pz+/WbNmPXnyBCF04cKFY8eO2dvbHzt2LDExMTMz08rKKjAwcM6cORwOByG0dOlSOp1ua2t75MiR2bNn//LLLwih0NDQwMDArVu36rxaE3NmcbZM57MFLUO/o6hWa2olaq4xLueayuXyWbNmde3aNSoqik6n79u376uvvoqPj9+7d29YWJiTk9O6desQQvv37z906ND69evNzMyEQuGWLVvodPqCBQsQQkwmMyMjQywWb9u2zcfHp127dosWLYqNjbWzs8OjYL4pXVwDbUV9pd9RFFcr+QK8FiE3N7eiomLSpEleXl4IoU2bNj158kSpVL432ZQpU0JCQlxcXLCHycnJd+/exaJIo9HevHlz9OhRbCWJNzaXrlJplHI1g6X37Q4DpN9RVKs0HD5eXztHR0dzc/O1a9cOGTKkS5cuvr6+/v7+/56MyWQmJiauWbMmIyMDC6qFhYV2rIuLS8vkEMMzoatUGv3+UA2Vfv988gWMyhIFTjNns9n79u3r1avXiRMnZs6cOXLkyIsXL/57sqioqL17944aNer8+fOPHj2aMWPGezPBqbx/U9SqpSIVhS8Nozb9jiKDaURn0GqleDWQnJ2dFy1a9Oeff27bts3d3X316tXp6el1J9BoNDExMRMmTBg1alTr1q0RQkKhEKdiPkhco+SbwhpRX+l3FBFCjl48cfX77TedyMnJiYuLQwhxOJw+ffps3ryZwWCkpaXVnUahUEilUmvrd7tw5XL5rVu38CjmY0iEqjZuhnv2n77T+ygKrJhZKbgc166uro6IiNi+fXt+fn5ubu7BgweVSqWvry9CyMHBITU19eHDhyKRyNnZOS4urqCgoKqqKiIiws/Pr6amRiyupyRnZ2eE0OXLl1NTU/EoODNZZGnbctvDQLf0Por4nWLi6+u7fPny+Pj4UaNGjRkz5unTp3v27HF1dUUIjR49mkajzZs379WrVxs2bOBwOGPHjh05cmRAQEB4eDiHw+nXr9+bN2/em6G9vf3w4cP37NkTFRWFR8HZz8X63puWIaPCVfxxewr7T23N5Rv07oqqUvndP8uHzLAluhDQRHq/VkQIufoY37tYTnQVBEv8s9yzM3Ryo8eosMPNu6fgcEROTYXC1IJZ7wTjxo0rLS3993CVSmVkZESj0ep91vnz583McOluNCkpadGiRfWOaryka9euGRnV8+v5Nk9WU6l0923pc3GBDlFhAxUhlPlMVJwja6ijN5FI1ITFNDHBcSXTtGMeDZV0/XSJRycTew9es+sChKFIFBFCd+LKuMb0zn3NiS6kpRnsglMMFdqKmJ4jrPIzJGkPa4gupEU9uV4prlZCDimAOmtFzJXfStq4ctp/ZhBdTj29USkTq7oPNYj+lymPalFECF0+XmIsoHcfRvEv6NWTJUyWUZ/RhtXvK4VRMIoIoaQblU9vVPUYZtXWn4L791MTq+/GlfcKtWrfDW7wRh3UjCJ2g5e7f5aJq5Wu3sYuPvyGjnPokcq38uxUcdrDmjbO3B4jLOEKDIqhbBQxZW9kL+4Ls1PETI6RvTuXzTXiCxgmFkyVUg+W2ohOE1YoxNVKpUKd81yCneXn3dNUYGno3dtREsWjqFX+prYkr1ZUrRRXK+kMmrBSlxdzaDSap0+fdu7cWYfzRAiZmDHUag1fwDA2Y7R25phbQwKpzFCiiCu5XB4YGJiYmEh0IUCPUee4IgB6DaIIAClAFAEgBYgiAKQAUQSAFCCKAJACRBEAUoAoAkAKEEUASAGiCAApQBQBIAWIIgCkAFEEgBQgigCQAkQRAFKAKAJAChBFAEgBoggAKUAUASAFiCIApABRBIAUIIoAkAJEEQBSgCjqAI1Gc3R0JLoKoN8gijqg0Wjy8vKIrgLoN4giAKQAUQSAFCCKAJACRBEAUoAoAkAKEEUASAGiCAApQBQBIAWIIgCkAFEEgBQgigCQAkQRAFKAKAJAChBFAEgBoggAKdA0Gg3RNeiruXPn5uTkMJlMtVpdWFjYpk0bOp0ul8vj4+OJLg3oH1grNt2UKVNkMllhYWFRUZGRkVFxcXFhYWFpaSnRdQG9BFFsuh49erRt27buELVa3b17d+IqAnoMotgskydPFggE2ocCgSAsLIzQioC+gig2S+/evd3c3LQPO3Xq1KVLF0IrAvoKothc06dPx1aMlpaWsEoETQZRbK6ePXt6eHgghHx8fDp27Eh0OUBfMVrmZarLFJVv5Wp1y7xaSxvR77/iUuPBgWFZqWKia8EFnU4zt2GaWjCJLoTKcD+umJcueXKtsrpc4eDJF1UpcX0tgBNjM0ZeutjchvXZIIvWzhyiy6EmfKNY+Fp6J64sZKodiwVbwnpPKlH9fahg8PTWlm3YRNdCQTgm5G2B7ObZ0sEzHSCH1MDl0UPnOsXtLRJWKoiuhYJwDMmjy5XdQ63xmz8gRI8R1g8uVRBdBQXhGMW8dInAioXf/AEhTC2ZBRlSoqugILyiKBWpzKxZTNg0pRxjMyadQdOo4SoCHcMrKjQaTVQBLQpqqipV0IxoRFdBNbDWAoAUIIoAkAJEEQBSgCgCQAoQRQBIAaIIAClAFAEgBYgiAKQAUQSAFCCKAJACRBEAUoAo4mXk6H5Hju5HCMWcO9lvwGctX8D1G5eDQ/yrqiobn0xbJyAWRBEAUoAoAkAKLdTj20fKy8vZ+tMPz549bWNr17t33//MmMNisbDh23/elPEqjU5nODu7hk2f3cnPHyG0LmIZjUbrFzJ4049rpVJJ+/Y+X85a2K6d9/4DO38/f+r8uatM5rtOyk6eOnLg112xv1/j8Xh37tw8fGRvbl62QGDm7t524fxvbWxaN16YSqU6c/b44SN7EULt2/mETZ/t4+OHEMrOzoz74+yTpw+Li984O7kOGTIydMTYpi37yNH9wqbPLijIizn3m5mZefduvcPnLdmwadWdOzcdHJymTP7PgAFDsSkbqX/PLz//ffkCj8sLCRlkb++knblSqTzw66579xPevi329vYbFTq+W7deTasT4IREa8Xi4qLw+TN8vP22Ru6eMGHa1Wt/7Yj6ESFUWVkRPn+GtXXrvb+c2Bl10NzM4vv1yyUSCUKIwWA8f/Hs8pWLe3Yfjb+QwGaxN25egxAKDhogkUgePLirnfnthOvdu/Xm8XiPHt9fvfabAQOGnj55cc2qTSUlRdt3bPpgbXv3RcXGnolYF7ly+Q+tWtl8+938vLwchNDOXVsfPkxcuODbTRt3DBky8ucdm+/dv9O0xWcymSdPHXZ0dL4Uf/eLmfPi/4r76utZIX0HXb50Lzio/5at3wtFQoRQI/XHxp2NjTuzcMG3u3YdsbW1O3J0n3bmO6J+PBtzYtTICSeO/xHYJ2TNuqU3b11tWp0AJySK4tmYE2wOZ0bYl507dR0xfMzM/8zF1mlnzh5nsdlLFq9sY2tnb+/4zZLVUqkkNu4M9iypRPLNktVtbO0YDEZI30H5+bkSicTNzaNNG/vbCdexacrLy168SOnbdyBC6NeDu/v07jt2zGSBwKxDh45z53x9715C+ssXjRRWXVN9+syxiROnd/Xv1rNn4JLFK/27dCuvKEMIrVq1ccuWXZ07de3k5x86Ymxbz3YPHt5tZFaN83D3GjF8DIvFCgrsjxDq0KFjcFB/BoMRHDRAqVTm5WY3Xv+5308G9ukX2CfE1MR00MDhnTt1xWZbW1t76e8/J08KGzF8jMBUMGRwaEjfQXWDCsiARFHMynrl4eFFp9Oxh4MGDl+44FuEUFb2aw8PLwbj3bY0n893sHfKyEjDHjo4OvN4POx/Y2MThJBQWIMQ6t9v8O2EayqVCiF06/Y1Lpfbq2cQ9ipeXh20L9rWsz1CKD39eSOF5WRnIoS0z2IwGBHrtmBbyEijOXfu5LSwMcEh/sEh/ukvX1RVNr0LJkdHZ+0yIoScnd/djYPL5WmXq6H6NRpNYWG+s7OrdpSnZzvsn4yMNLlc3tX/n1tc+fl2ycp6XV1T3eRSgc6RqK0oFovMzMz/PbyivMzOzqHuEA6XK5FKsP+NjOr/NekXMvjwkX1Pnj7s6t8tIeF67959GQyGSCSqra1ls//pVBeLsUTSWK/eIpEQIcRhv98Vr1qtXrZ8oUIh/+8X4X5+/ibGJvMXzvyUJX4fjfb/eqn496I1Ur9YLFapVFhoMRwOt279/66tsqJcYCpAgBxIFEU+31hcXyR4fL6sVlZ3iFQisbdzbHxu9vaObm4ed+7c8PRsl5T8eNPGHQghDoeDEJLJ/umwDHtFSwurxgurN64Zr9LT059HbtnVpXMANkQkEraywrG/yUbq5/P5dDq9ts4bJf3fr5WlVSuE0OKvV7z3i2Zt/YGdVaAlkWgDtW3b9s+fJyuV7zrzv3rt0pJv5qpUqrae7dPSUhWKd51W1QhrcvOyXVzcGp0Zwnbe3L9/59q1S6amAqzhxGAw2nq2e/78mXYa7H9XN49G5uPu3pbBYCQ/e4I91Gg0y5YvvHTpz+rqKoSQNns5OVk5OVnNeAM+rJH6aTSajY1t3VH37idg/9jbObLZbIRQJz9/7M/ZydXJ0UW7YQ/IgERRHDpkpFwu3/bThkeP799OuL5vf5SlVSs6nT58+BixWLR12w8lJcU5OVkbN63msDlDBo/84AyDgvoXlxT99VdccPAAbRN01MgJCXduxMT8ViOseZr0aNfubZ07dfVwb9vIfIyNjfv3GxIbeyb+r7inSY+iorc8fny/XTtvZydXBoNx6vTRGmFNXl5OVPSWrv7dikuKdPeW1KOR+oOD+t+6fe36jcsIod9OHn7xIgV7Co/HC5s++8jRfSkpSXK5/Oatq0uWzt3+84f3G4OWRKINVHt7x00bd0RGfh//VxybzR44YNgXX4QjhOztHNas3nT06P6Jk4cJBGbt2nn/vH0/tmOjcXZt7Nt6tnuZkbZg/lLtwAEDhpaWvT115mj0rq02Nq39u3T77xfhH5zVwgXfbv9509ZtP6hUKnc3z4i1W7BdLCuWrz98ZG/oyL52dg4rvvu+vKJs1eol02eMPXzwbLPfj/o1Uv+Uz2dWVVVGRW+J+P47Hx+/uXO+/mHDSuyeKBMnTHNz8zxx8tCTJw/4fOMO7TsuXrwSpwpB0+B1+xqZWH1sQ86Epa4fMS3QM4fXvg7/yZ3oKqiGRBuoABgyEm2gEmv4iKCGRn377VrsmGRzpKQkLV+xqKGxx46eFwjMmvkSQK9BFN/Zu/dEQ6PMzSyaP38fH79GXgJyCCCK79i2bkOBlwD6C9qKAJACRBEAUoAoAkAKEEUASAGiCAApQBQBIAWIIgCkAFEEgBQgigCQAl5RpBlpLFuzcZo5IJBarWnt8n7fIqD58Ioim0uvqVIIKxU4zR8QpbyoVqXE5cI6A4fjBqpHJ5OSXAl+8weEKM2Xefh++Lpt8KlwjGKPYZYv7lUXZUEaqSMzuabwlahziA4uVQHvwesqfoxarTm5Jd+9k6mxGdOiNRvPlwI4otE0ZW9qhRXyggzJuEX2RJdDTfhGEZN0syo/Q4IQreJNLa4vpFAqFQoFj8vF9VVIRSKVslgsxv860cKJRRu2kRFy9OL69ITrKvHSElFsAVKplMvlRkRErFq16r2OfalNKpVGRkauWrWqtrYW62ER6CkqRHHXrl1+fn49evQguhAiXbhwoaysbPr06UQXAppI7w/xX7lyhc1mG3gOEUJDhw6trq5+/Pgx0YWAJtLXtaJMJtuyZcuqVatkMhnWfT2ou6G+evVqomsBn0Zf14qLFi3q06eP9jYSAMPlchFCvr6+ixY12LscICc9Wyu+fPkyJSVl7Ngm3tnX0Bw/fjwwMNDeHg4/6AF9Wiu+fft23bp1QUHN7ZLUcPTp02fevHkikYjoQsCH6cda8erVqx06dOBwOGZmcFzrk4nF4jdv3pSVlXXv3v0jJgfE0IO1YkxMzKVLl2xsbCCHTcPn811cXI4fP3716lWiawENIvVa8fLly/3798/MzHRz+/DdFMEHYe8k9q4SXQt4H3nXimPGjJHJZAghyKGuYO9kcXHx3Llzia4FvI+Ma8X09HQvL6+CggLY9YcTbPWYkpLi4+NDdC3gHXKtFXNzc/39/bE2IeQQP9jqkc/n9+7du7S0lOhyACJRFIuLixFCFRUVjx49at26NdHlGARXV9dLly5hUayoqCC6HENHiijGxMQsWbIEIdSpUyeiazEsPB6vffv2CKHPP/8c9q8Si+Ao5uXlIYRYLNaxY8eIrcTAxcfHYzvJ8vPzia7FQBEWRY1Gs2zZspSUFITQ8OHDiSoDaA0dOhQhdPPmzYiICKJrMUTE7EGVSqWFhYXZ2dlwgIuEYmNju3fvzmazBQIB0bUYkJZeKxYXF0+aNEmlUrm7u0MOySk0NNTa2loqlc6cObOqqorocgxFS68VDx482LNnT09Pz5Z8UdA0SUlJaWlpkyZNIroQg9BCUbx27dqlS5c2b97cAq8FdG7hwoVTp0719/cnuhAqw30DVS6XY2eTws4A/RUREfH7778jhJRKJdG1UBa+a8Vff/21Xbt2cG0OZVy4cEEkEk2YMIHoQigIx7XilStXpFIp5JBKhg4dmpubC51Z4QGXtaJCoSgvLzc2NjY2Ntb5zAHhRCJRTU2NjY0NHeeukA0KLmvFvLy8BQsWQA6pytjYeMaMGZWVlUQXQim4RJHFYsEp3dTWpk0bBoNBdBWUQsbrFQEwQLisFRUKBXbRE6CqN2/eqFQqoqugFBzbinjMGZAEtBV1DtqKoCmgrahz0FYEgBSgrQiaAtqKOgdtRdAU0FbUOWgrgqaAtqLOQVsRAFKAtiJoCmgr6hy0FUFTQFtR56CtCJoC2oo6B21FAEgB2oqgKaCtqHO4bGPk5eV99913p0+fxmPmgEDjx49nMpkMBiMtLc3Z2Rn7n8lk7t+/n+jS9B4uUYS2IlVlZmbSaDTs/6ysLIQQjUaDuzXqBLQVwSeYO3duYmJi3X40XFxcTpw4wWQyCa2LCqCtCD5BWFiYubm59iGdTh85ciTkUCfguCL4BAEBAV5eXtqHDg4O48aNI7Qi6oDjiuDTzJgxw9TUFCHEYDBGjRrFYrGIrogioK0IPtncuXPv37/v5OR06tQp2DrVFVz2oGL9oOrjilFcrVSriS6C9CaMCcvKKBo94nOZiCZD0HX/B5iYf1TKcFkrZmZm6t1xxYTzpS8fiyxt2dWlcqJrAdRh2YZdmCnx8DPpNcqKxW6sPQjHFZFKqfltS55Pb4vhX5pzjeG8SqBj8lp1RVHtgVVZYatduMYN9qcObUV0fFNet2GtrB24RBcCKO7IutdzIt2MjGj1jjX044rJt6rc/Ewgh6AF9J1km3C+rKGxhn5c8U2mlG8K+wBBSxBYsXKeixsaa+jHFTUaZG4NR8ZASzCxYBqbMRXy+puEuETRwcFhx44deMxZ56reKuDoBWgxJXmyBpqKBt9WBIAkDL2tCABJGHpbEQCSMPS2IgAkAW1FAEgB2ooAkEKDp1yWlTV4WsAHGRsbb9y4sTlzQAhZWVk15+kA6Bdc1op0Ol0gEOAxZwCoCpcoajQa6CQTgE+CSxRVKlVNTQ0ecwaAqnCJIo1GMzLCZc4AUNXHXin7+vXr8PDwekft3r3bxcVl3bp1iYmJy5YtCwoK0rYVKyoqJk+evHnzZl9fX4TQmDFjxOJ3Z6YLBAJLS8suXbpMnjyZy4VrlHARc+7krt3brl5+QHQhZLdm7VKRSLg1cjeBNXzaRevTpk3r0KHDewO1J9bQ6fQDBw50796dxWKp1eq6Hddq9erVa/jw4RqNpqSkJD8//8qVK0lJSRs3bjQ2Nm7GUoD6tW/nPXXKF0RXQVLrIpZ17dp9yOBQhFCfPiEKBcEdqXxaFB0dHbH1W7169Ojx5MmTs2fPTpgwQSgU1u27VsvS0rLuHEaOHPnll19GRkauXbv2EysHH9aunXe7dt5EV0FSL1++6Nq1O/Z/SN+BRJej07Yim82eNm3aqVOnSktLP7KtaGVlNW3atHv37uXm5uqwElzdu3/nq69nDx7a6/OpIzduXlNeXoYQSkt/Hhzin5b+XDvZlKkjd+3+CSH0+/nTo8cOeP06Y8Kkof0GfDbzvxNfvEi5e/fW8BFBg4f2Wr3mm6qqd/cMHTm63/nYM9E7twaH+I8a0//HLRESiWTl6sXBIf7Twsb8/fcFbDKRSHTw0J4586YPHtoLexWZTIaNWrN2acT33/2yd0dwiP+t29dizp0M6R+AELpz52ZwiP97fwUFeQghpVL5y94dM2aOHzq8z7ffLbh3L+Fj3oQaYc2WyO+DQ/xHju63/ocVJSXvTq6SSCTrN6wcO37QwME9Zn855XzsGWx4dnYm9v6sWr0kOMR//MQhu/dsV6lUDx/dCw7xT01N1s4Zeyfv3b+DEHr+/NnSb8NHhAZPnT561+6ftK2bmHMnx4wbmHDnRkj/gKidkQ19KAihxMTbP2xYOWHS0MFDe329+MunSY+w4cEh/kXFb7ZEfj88NAh73xYvmdO0RWjq9+h9OosijUZTqVTDhg2ztLQ8ePDgxx9X7N69O0IoJSVFV5XgKuNV+nfLF3bq1PXQr2cXzF+amZmx+ccPrM+ZTKZIJDx05JfIH3f9EXtDoVBs2LQ6/q+4/ftOHj8am5KadOr0Ue2UJ08ddnR0vhR/94uZ8+L/ivvq61khfQddvnQvOKj/lq3fC0VChNC530+e+O3QhPFTN/ywffbshTduXj58ZK92DlnZr7OyX//w/baOPp20NXh7+27bukf75+bm0drG1tKyFUJoR9SPZ2NOjBo54cTxPwL7hKxZt/TmrauNL5FSqVz23YKy8tJtW/fMD//mbWnJsuULlEolQmjZ8gVv3hR8H7H19MmLffqE/LxjM/bzhHWXunXb+pCQQX//lbjiu/Wnzxy7fuNy505dTYxNbt2+pp15QsJ1E2OTrv7dCgrzlyydK6uVRUcd/H5dZFbWq6++noW9CovFkkjEcXFnv1sWMSp0fEMfikwm+2Hjytra2mXfrtvww3ZHR+cVK7+qqChHCP118Q5C6Jslq/6IvfHe0n3qInziN6hBn7aBun79+veGBAQEREREYMcSseZieHj4ihUrQkND/92qrFerVq1oNFp5efknVUKU1JQkDocz5fP/GBkZ2di09mrbPiv79QefpVAopk+b5eDghBD6LKDnud9P7ti+38LCEiHk59slMzNDO6WHu9eI4WMQQkGB/SO3ru/QoWNwUH+EUHDQgCNH9+flZnfo0HH8uCmBfUKcnFzelZSa/ODh3dmzFmA/iMXFb/bsOsrhcOoWIBCYdfLzx/6PjTtbWJgfveMgl8utra299PefkyeFYS86ZHBoamrykaP7AvuENLI49+4npKWlHj541tHRGSHk4OB0+syxioryrOzXKSlJv+4/5eLihhD6fPKM+w/uHD6yd9OGn7EnBvbpFxTYDyHk69u5ja1dRkZav5BBwcEDbt2+OnfOV9g0t25fCwkZRKfTr1yJZzKY36+LFAjMEEJLFq+a9PnwhDs3ggL70Wg0mUw2ceL0zp26IoTOnTtZ74fC4XD27z3J5XKxObTz8o6NO5uSmtTI0t27f6cJi/DBL8DHaO5uGxMTk/em6dKli7+//44dO/bs2aOLCsnF28dPJpN9t2KRf5fPunfvY2/noP2KN87ZyRX7h8fjmZtbYDlECHG5vJK3/5w6j325EUJ8Ph8h5Ozspp0MISQU1mA/zw8fJW7avOZ1Zga2ljA3t9DOwcnR5b0c1vX6dUb0zsgVy9e7uXkghDIy0uRyeVf/7toJ/Hy7xP8VV11TLTBtcLsmM/MVj8fTlurp4bVy+XqE0NVrf3E4HOxL/L9R7a5e++ufh57ttP8bG5uIREKEUFBQ/7g/YjJepXt6eGVnZxYU5H37zRqE0PPnyV5eHbAUIYRat7Zt08b+WcpTLAkIIa+2776KjXwoEol4/4HopOTH2k1WbXOgXtnZr5uwCDqhy902WrNnz54zZ058fHxSDJn7AAASNElEQVS3bt0+OPHbt281Go2+nHHq6eG1aeOOW7eu7t0XtWv3T106B4RNn+3t/eH3RHtbwvf+b2QyhFC9Te69+6IuXjw/e/bCrv7dbWxa7z+w82J8rHYsi81uaOY1wpqVq78OHTFO+23GvknzF858b8rKivJGoigWi9jsetJeXl7G4fy/41I8Hk8qlTS+OH6+XczNLW7duurp4XU74XqrVtbY+ykSCdNfvggO+X+/dJUV/2w9aW/X0dCHUlJSvPCrLzp3Cli1YkP79j40Gq3/wA98IZu2CDqBSw+8Dg4Ow4cPP3z48MfkNj4+HiHUtWtXPCrBw2cBPT4L6DEj7MvHj+/HnPtt+YpF52LqaTAoVbj0YK/RaP74M2bsmMnDho7Chnz8D/P69cttbGznfLlIO8TSqhVCaPHXK+zsHOpOaW3d2JXfPB5fKpWo1er3vpd8Pl8mk9YdIpaIrSxbNV4VjUYLDh6QcOfGFzPnJSRc799vCDbcwtLKx8dvRtiXdScWmJrVO5N6P5QbNy/L5fJl367DDlw3vj5sziLoBF7noE6cOBEhdObMmcanTE9PP3PmTP/+/a2trfGoROeSkh7ff3AXIWRl1WrgwGHz5i4WioTFJUVsFhshpP35FIlEZWWleBSgUCikUqmV1bu3Sy6X30289TFPPPHboazs1xFrt9Q93mtv58hmsxFCnfz8sT9nJ1cnRxcej9fIrLzatpfJZC8z0rCHeXk5i76elZn5qq1ne5lM9ur1S+2UaWmpznU29hrSN2hAbm72vXsJr16/1EbRzdXj7dti346dtbWZm1lot4rrauhDqampNjEx1Z5A8sHdUQihJi9C831aFPPy8pL/5d9XCatUKrVaPXXq1L///vu9UeXl5donHjt2bMmSJa1atZo58/0NJNJKfZ68dt3SP/48V1VV+SIt9dzvJ62sWrW2sXVwcDIxNrkYH6vRaJRK5aYf15iYmOJRAIvFcnR0jv8rrvBNQXV11Y+RET7efkJhjXZHf72Sk5/s2x89ccK0rOzXT5MeYX9v35bweLyw6bOPHN2XkpIkl8tv3rq6ZOnc7T9varwGf/9udnYOe/fuuJ1w/eGje9t/3lT6tsTJySUgoEebNvbbtv2Q/vJFRUX5gV93paWlThg39YML1aFDR2trm4OH9ri6ujs7v2tUjx37uVqtjt61VSaT5efn/rJ3x3++mFDvTrKGPhRXV4/y8rK4P2KUSuX9B3efPHkgEJi9fVuMHXhr1cr60aN7T5MeYe1tTJMXofk+bQP1yJEj/x44bdq0yZMn1x2CnYM6dOjQuLi4vLy8uqMSEhISEhKwaxrbt28fFhbWt29fM7P6tzpIaPy4KVVVldE7I7f9tIHFYvUNHvjTtr0MBgMhtGrVxp93bO7br6uVVavZsxZWVJTjdBOEVSs27Ny1NWzGWA6HM3fO135+/g8e3B01pt/hQzENPeXS338ihHbu2lZ3YPi8JWNGT5w4YZqbm+eJk4eePHnA5xt3aN9x8eKVjRfAYDAif9y1cfPq1Wu+QQh1795744afsTdhfcTWPb9snztvOovFcnX1+D4i0sfH72MWKiiw/+kzx76YOU87xNTE9MD+UydPHp49Z0peXo6XV4dvlqzy9PD693Mb+lBC+g7Mzc06cnTfT9s3dvXv9u3StSdPHTnx2yGhsObrr5Z/Pvk/Bw/tefDw7m8n/qy7aE1ehGZq8J4Zzbzwt/laZkfOiU15vUa3NreBXolBSzi2PnPWBlc6s579dnC9IgCkgMseVJVK1dA5qEAvpKQkLV+xqKGxx46e1x7uA7qCSxThekV95+Pjt3fviYbGQg7xgEsUoW8bCrBt3YboEgwLtBUBIAVcoqhUKisrP3xmAwBAq8EN1OYcS8jPz9+1axf01Q/Ax4N7ZgBACnDPDABIAe6ZAQApwP0VASAFaCsCQArQVgSAFAy9rWjemkmDU/RAS7Fx4jR04ZyhtxVpRrSK4lqiqwAGobpMLq5RMuq7Qqqx6xUNROrdamGlyruXxUdMC0Cz5LwQ1ZTKeo6o/+QZQ28revcQFGRIcl6IiC4EUFytVHU7prihHEJbESGExi60e/mw6uXDqqpSgm9gAihJVKXITxedjsz+7w+ujUyGy0VSetRWxJqLYxfYP/y74taZIjaPXlECgfwwlUpNp8P+rg+zduBUl8rdfI3nRro3PqWhtxXfo5RrVCp4Qz5s9OjR+/bts7S0JLoQsqMhxOJ+1G8WLmtFhUJRXl6uRytGLQaLxkANdt0NtJRqKYtDY3/clwx8DGgrAkAKhn5cEQCSgHNQASAFQz+uCABJQFsRAFKAtiIApABtRQBIAdqKAJACtBUBIAVoKwJACtBWBIAUoK0IAClAWxEAUoC2IgCkAG1FAEgB2ooAkAK0FQEgBWgrAkAK0FYEgBSgrQgAKUBbEQBSgLYiAKSAY1sxMzMTj5kDwl28eNHe3p7L5RJdCKXg2I9lZmbm559/XlNTg99LgBZ248aNsWPHJiYmbt++nc/nE10OpeDbO3h6ejqdTvfw8EhOTvb19cXvhQDeHjx4sHPnTisrq/DwcBcXF6LLoaAW6qh/zpw57u7uixcvboHXArqVmpq6c+dOhNC8efO8vb2JLoeyWu6eGUlJSX5+fomJic7Ozra2ti3zoqA5srOzo6KiysvL582bFxAQQHQ5FNfSt6/JyckJDw/fvHlzhw4dWvJ1wScpKSmJjo5OS0ubP39+YGAg0eUYBGLuJFVQUGBvb3/gwIHp06czGLjcQgc0jVAojI6Ovn37dnh4+JAhQ4gux4AQcycge3t7hJCZmdn48eMJKQD8m0ql2rFjx/Dhwz08PC5evAg5bGGkuL/ilStXiouLp0yZQnQhhuvAgQO//PLLvHnzpk+fTnQtBooU98fr27dvaWlpbGws0YUYohMnTvTs2bO2tvbBgweQQwKRYq2IkcvlLBZr4cKFQ4cOHTBgANHlUF9sbGx0dPSgQYPmzZvH4XCILsfQkWKtiGGxWAihlStX3r17FyFUVVVFdEWUdfny5dDQ0OTk5FOnTi1evBhySAYkWiu+JyMjY9OmTevXr2/Tpg3RtVDHnTt3oqOjnZycwsPDsZ1ngCTIG0WEUHJycn5+/rBhw7CDH0SXo9+SkpKioqL4fH54eLinpyfR5YD3kTqKWhs2bKiqqtq8eTONRiO6Fv3z8uXLnTt3isXi+fPn+/n5EV0OqJ9+RBEhdPXq1Z49e1ZVVTEYDCsrK6LL0Q8FBQXR0dF5eXnz5s3r2bMn0eWAxuhNFDHV1dXjx49funRpSEgI0bWQWkVFRXR09OPHj8PDw/v37090OeDDSLQH9WMIBIJLly6ZmZlhJwYQXQ4ZyWSyyMjICRMm+Pr6xsbGQg71hZ5FEdOlSxeEEJPJ9Pf3F4lERJdDIrt27QoJCbGzs8MOVxBdDvgEehlFTGBg4KNHjzQaTWlp6enTp+uO6tWr16hRoyQSCXHV4aioqCg0NDQoKKjuwMOHDwcEBLDZ7Dt37kyaNIm46kAT6XEUMSYmJlZWVtnZ2evXr9cOlEgkubm533zzDaGl4WXlypUFBQXV1dXYw7NnzwYGBlZXVycmJs6cOZPo6kAT6dlum0YIhUITE5NDhw7t3r1bpVJhp+/MmTNn6tSpRJemS1FRUcePH1cqlQghDodjamrau3fv+fPnGxsbE10aaBbqXCtoYmKCrSKwHGIntZ44caJLly7t27cnujrduHfv3oULF7AcYiv/mJgYGxsbousCOkCdtSImICBArVZrH2o0Gnd391OnThFalG7I5fLx48cXFBTUHWhqanrt2jXiigI6o/dtxboGDRqkUCjU/4MQotFoWVlZ69atI7o0HVi5cmV+fj5CSF1HRUUF0XUB3aDOBirWdnJycsJ66JDL5UqlksViMRiM5ORkhJBMrMpMERfl1FYUyaUiJZvHqCqtJbrk+gmsWHKZmmtMt7Jl2blzXLz5LLbRs2fP7O3t6XS6RqNRKpV0Op3JZNJotDFjxsTExBBdMmguqm2gvketVisUivw0xdOb1eVvak1a8UyseEYMIwabzmAxSHtCqwYhpUyplKtUSpXwrURYKrF143n34Dq3N4augKiK4lHMz5DcPFeOaHRzRwHfTI+vyhNVyipyqlhsTeAoK1tXPV4Q0BDKRlGtRn+fKCt7I7dwNOMJ2ESXoxviCmllQY2dOydotAVpV+mgaSgbxbM7ChGTY+VsRnQhuvf2dQWHrRoxC+7VRSnUjGLsL0U0Dt/UmrL3VynPr+FzFYOmWhNdCNAZSh3MwJyNKkRsKucQIWTpYCqVMS8cgFs7UwfVongjppTG5AhsqJxDjLm9qVhCv38JjitSBKWimP9S8iZHYelEwfZhvazdLV4nS0sLZEQXAnSAUlG89Xu5uZ2h5BBjamt663w50VUAHaBOFF89FWqM6FyqHLf4SCZWPHGNpvC1lOhCQHNRJ4rJt2ssHAVEV9GgmD9+3BKFyxW95vaCpzeq8ZgzaEkUiaJUpCovquUJDPE0FJNWvJznIkoelDIoFIliVorI1JpHdBWEMbPlZaeKia4CNAtFzi1+m1/Ls8AriiqVMv7KnrSMO1VVxS5Ovj0+G9e+7bs+RddsHDgwZJZYUvX3tf1sFretR7fQwV+bmlohhGprJcfPrn6d9cjWxr1719E41YbhW/CKc2tdfeBCfj1GkbVi2Rs5g4HXsvz+Z+TtxN96fTZu+eLzPh36Hjm57Fnqu6t16XTmjYRjNJpRxHd/L11wOjs3+dL1fdio0+d/KCvPnx0WPX3S5uK3WekZd3AqDyFkxDAqL5LjN3/QAigSRYlQxWDT8ZizQlH7KOlC397TuweM5vMEn3UZ0anjwMs3DmgnsLKw7xc4g8s1MTW1auveraAwHSFUXVOanHoluNdUJwdvUxPLYQPDmQwc27FMNl1crcRv/qAFUCSKbB4dpyjmv0lTKuWe7p9ph7g5dy4qeS2WvNtpaW/XTjuKyzWV1YoQQhWVhQghG2sX7SiHOpPpHIPDYLAo8lEaLIq0FSU1SpVCTWfoPo0yqQghtHP/rPeGC0XlfB527KSeq5WwoLJZ/zRfWSyuzmvTUslVMrEKv/mDFkCRKHKN6cpaFYvL1PmcsX0wY0O/s7JwqDvcXNDYNUpYSuWKf05Jk9XiuIdTWavim1LkozRYFPn8+AKGUo7LaqGVpSOTyUYIubt2wYYIRRUajYbNbmyHrblZG4RQTt4zbLtUqVS8ynzA55vjUSFCSFGrNDbDZfsctBiKNDBsndkyIS59RrHZvAHB/718/UBWbpJCKX+Wem3vofnn/vyx8WeZCaydHX0vXdv7tjRXoag9fmYVwvOqe7lIbutsWGf8UQ9F1oquPvzUu8XIzQKPmQf3ntrG1vP67SOvMh9yOMbODj7jQpd/8FmTxqyJ+WPz9t3TlCpF107DAjqPeJ52E4/yEEI1pRJXH0ucZg5aBnWu4v91TY59x9Ysnu6biyQnqa6tyiufvNThI6YF5EWRDVSEkHcP06oSQzz5S1Qq7tjLhOgqQHNRZAMVIRQw0OLxN5lWDqZGDZx289vZtc9f3q53lEqlpNPrfysmjl7t3S5QV0Veu3X42u0j9Y7iso2ltfXfKzJs8o/uLl3qHSWXKoWlYu8ezrqqEBCFOhuoCKGkm1XpT2tbt7Wqd6xQVKFQ1H/Bu1xRy2LWv9vDmG/BYunsRBmpVCiVCeuvQS5r6IUaqaEw9W3XEGPPzrBW1HuUiiJCKCaqkGttxjM1iKulROVSVCsaNhN6YaQC6rQVMWPm2+U8LFar1B8xrX5TyJQlL0shh5RBtSgihKatdCpMoXivhCqluuhFydSVTkQXAnSGglE0NmOMCbdNvZwtE1HzuiFJlSzjdt7EJfYsNgU/PoNFtbaillqtObohz9ja1NLBlOhadKkir1ouFE9cAkcRqYayUcTcPl/24l6NtbuFuZ3e72OsyK8pflXRpZ/5ZwNxOakIEIviUcR6oLoRU/bmtZQj4Bhb8YwtOXhcS4UTlVIlLJWKyiQKmdzRk9dnlCUTNkopivpRxMgkqpzn4pdPxKIqZXWpnMWlm7bi1IpJeuU7k0MXVdTKpSpzW46xgN62M9+lAx9CSG2GEsW6FHK1pEYlEarUKpIuO51O45nSeaZ0BhPiZygMMYoAkBD86AJAChBFAEgBoggAKUAUASAFiCIApABRBIAU/g+HvjCmcWK0nAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage, RemoveMessage, HumanMessage\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0) \n",
    "\n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id = m.id) for m in state[\"messages\"][:-2]]\n",
    "    \n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return \"END\"\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"convo_call_model\", call_model)\n",
    "workflow.add_node(\"summarize_conversation\", summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"convo_call_model\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"convo_call_model\", \n",
    "    should_continue,\n",
    "    {\n",
    "        \"summarize_conversation\": \"summarize_conversation\",\n",
    "        \"END\" : END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'convo_call_model': {'messages': AIMessage(content=\"Hey Usman! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--da566891-f1df-4d43-af71-69aed65c5494-0', usage_metadata={'input_tokens': 6, 'output_tokens': 19, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\" : {\"thread_id\" : \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\" : [HumanMessage(content = \"Hey i'm usman\")]}, config, stream_mode = \"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fceadd2-e0cc-431c-b928-7bc5bedbe8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Usman! It's good to connect with you. What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Usman\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk[\"convo_call_model\"][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b5718-9b68-4f29-b558-6281619fcf83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Ozman\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Ozman\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Ozman! It's nice to meet you. How can I help you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = [HumanMessage(content=\"hi! I'm Ozman\")]\n",
    "\n",
    "for event in graph.stream({\"messages\": input_message}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: convo_call_model. Type: on_chain_start. Name: convo_call_model\n",
      "Node: convo_call_model. Type: on_chat_model_start. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chat_model_end. Name: ChatGoogleGenerativeAI\n",
      "Node: convo_call_model. Type: on_chain_start. Name: should_continue\n",
      "Node: convo_call_model. Type: on_chain_end. Name: should_continue\n",
      "Node: convo_call_model. Type: on_chain_stream. Name: convo_call_model\n",
      "Node: convo_call_model. Type: on_chain_end. Name: convo_call_model\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "\n",
    "async for event in graph.astream_events( {\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='Okay', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 3342, 'output_tokens': 0, 'total_tokens': 3342, 'input_token_details': {'cache_read': 0}})}\n",
      "{'chunk': AIMessageChunk(content=\", let'\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='s dive deep into the current state of astronomy! \"Astronomy now\" is a vibrant and', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' rapidly evolving field, driven by technological advancements, ambitious missions, and a constant quest to understand the', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=\" universe. Here's a comprehensive overview:\\n\\n**I. Key Research Areas & Hot Topics:**\\n\\n*   **Exoplanet Science:**\\n    *\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='   **The Habitable Zone & Beyond:** The search for Earth-like exoplanets within the habitable zones of their stars (where liquid water could exist)', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' remains a central focus. However, research is also expanding to consider planets outside the traditional habitable zone, exploring possibilities like subsurface oceans or alternative biochemistries.\\n    *   **Atmospheric Characterization:** The James Webb Space Telescope (JWST)', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=\" is revolutionizing exoplanet atmospheric studies. It's detecting molecules like water, methane, carbon dioxide, and even potential biosignatures (indicators of life) in exoplanet atmospheres. This includes looking for disequilibrium chemistry, where the presence\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' of certain molecules suggests biological activity.\\n    *   **Exoplanet Diversity:** Astronomers are discovering an incredible diversity of exoplanets, from hot Jupiters to super-Earths to mini-Neptunes. Understanding the formation and evolution of these diverse worlds is a major challenge.\\n    *   **Direct', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' Imaging:** Techniques for directly imaging exoplanets are improving, allowing astronomers to study their properties in more detail. Future missions are planned to enhance direct imaging capabilities.\\n*   **Cosmology & the Early Universe:**\\n    *   **Dark Matter & Dark Energy:** The nature of dark matter and dark energy remains a', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' profound mystery. Current research involves:\\n        *   **Mapping Dark Matter Distribution:** Using gravitational lensing and galaxy surveys to map the distribution of dark matter in the universe.\\n        *   **Searching for Dark Matter Particles:** Direct and indirect detection experiments are searching for dark matter particles in the lab and in space.\\n        *   ', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='**Exploring Modified Gravity Theories:** Some researchers are exploring alternative theories of gravity that could explain the accelerated expansion of the universe without invoking dark energy.\\n    *   **Cosmic Inflation:** Evidence for cosmic inflation (a period of rapid expansion in the very early universe) continues to grow. Researchers are studying the cosmic microwave background (CM', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='B) for signatures of inflation, such as primordial gravitational waves.\\n    *   **The Epoch of Reionization:** Understanding how the first stars and galaxies reionized the universe after the Big Bang is a key area of research. JWST is providing unprecedented views of galaxies in the early universe, helping to shed light on this process', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='.\\n*   **Galaxies & Galaxy Evolution:**\\n    *   **Supermassive Black Holes (SMBHs):** The relationship between SMBHs and their host galaxies is a central question. Research focuses on:\\n        *   **SMBH Feedback:** How SMBHs influence the evolution of their host galaxies through outflows', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' of gas and radiation.\\n        *   **SMBH Mergers:** Studying the mergers of SMBHs in merging galaxies.\\n        *   **The First SMBHs:** Understanding how SMBHs formed in the early universe.\\n    *   **Galaxy Formation & Assembly:** Astronomers are using simulations and observations to study', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' how galaxies form and assemble over cosmic time. This includes:\\n        *   **Mergers & Interactions:** The role of galaxy mergers and interactions in shaping galaxy morphology and star formation.\\n        *   **Gas Accretion:** How galaxies acquire gas from the intergalactic medium to fuel star formation.\\n        *   **The', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' Circumgalactic Medium (CGM):** Studying the diffuse gas surrounding galaxies, which plays a crucial role in galaxy evolution.\\n    *   **Star Formation in Galaxies:** Understanding the processes that regulate star formation in galaxies is a major goal. This includes:\\n        *   **Molecular Clouds:** Studying the properties of molecular clouds,', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' the birthplaces of stars.\\n        *   **Feedback from Star Formation:** How star formation influences the surrounding gas and dust.\\n        *   **The Initial Mass Function (IMF):** Determining the distribution of stellar masses at birth.\\n*   **Stars & Stellar Evolution:**\\n    *   **Stellar Populations', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=':** Studying the properties of different stellar populations in galaxies to understand their formation histories.\\n    *   **Binary Stars:** Binary stars are common and play a crucial role in stellar evolution. Research focuses on:\\n        *   **Mass Transfer:** How mass transfer between stars in binary systems affects their evolution.\\n        *', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='   **Supernovae from Binary Systems:** The role of binary stars in producing certain types of supernovae.\\n        *   **Gravitational Wave Sources:** Binary black holes and neutron stars are important sources of gravitational waves.\\n    *   **Stellar Explosions:** Supernovae, novae, and other stellar explosions are important', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' sources of heavy elements and play a role in the evolution of galaxies.\\n    *   **Neutron Stars & Black Holes:** Studying the properties of neutron stars and black holes, including their masses, spins, and magnetic fields.\\n*   **Solar System Exploration:**\\n    *   **Mars Exploration:** Missions to Mars are', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=\" searching for evidence of past or present life and studying the planet's geology and climate.\\n    *   **Ocean Worlds:** Exploring ocean worlds like Europa and Enceladus, which may harbor liquid water oceans beneath their icy surfaces.\\n    *   **Asteroid & Comet Missions:** Missions to asteroids and comets are\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' providing insights into the formation and evolution of the solar system.\\n    *   **Planetary Defense:** Developing strategies to protect Earth from asteroid impacts.\\n    *   **Space Weather:** Understanding and predicting space weather, which can disrupt communications and power grids.\\n\\n**II. Key Technologies & Observatories:**\\n\\n*   ', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='**Ground-Based Telescopes:**\\n    *   **Extremely Large Telescopes (ELTs):** The Extremely Large Telescope (ELT), the Thirty Meter Telescope (TMT), and the Giant Magellan Telescope (GMT) will revolutionize ground-based astronomy with their unprecedented light-gathering power and resolution.\\n    *', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='   **Adaptive Optics (AO):** AO systems are constantly improving, allowing ground-based telescopes to achieve near-space-based image quality.\\n    *   **Radio Telescopes:** ALMA, the Very Large Array (VLA), and other radio telescopes are providing unique insights into the universe at radio wavelengths.', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' The Square Kilometre Array (SKA) is a future radio telescope that will be the largest and most sensitive ever built.\\n*   **Space-Based Telescopes:**\\n    *   **James Webb Space Telescope (JWST):** JWST is the flagship mission of the decade, providing unprecedented views of the', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' universe in infrared light.\\n    *   **Hubble Space Telescope (HST):** HST continues to make valuable observations in the visible and ultraviolet wavelengths.\\n    *   **Chandra X-ray Observatory & XMM-Newton:** These X-ray telescopes are studying black holes, neutron stars, and hot gas', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' in galaxies.\\n    *   **Future Missions:** Several future space-based telescopes are planned, including the Nancy Grace Roman Space Telescope (which will study dark energy and exoplanets) and the Laser Interferometer Space Antenna (LISA), which will detect gravitational waves from space.\\n*   **Computational Astronomy:**\\n    *', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='   **High-Performance Computing:** Astronomers rely on high-performance computing to run simulations of the universe and analyze large datasets.\\n    *   **Machine Learning & Artificial Intelligence:** Machine learning and AI are playing an increasingly important role in astronomy, helping to identify patterns in data and automate tasks.\\n    *   **Data Visualization', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=\":** Advanced data visualization techniques are used to explore and communicate astronomical data.\\n\\n**III. Recent Discoveries & Breakthroughs:**\\n\\n*   **JWST's Early Universe Observations:** JWST has discovered galaxies at incredibly high redshifts, pushing back our understanding of galaxy formation to within the first few hundred million years after the\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' Big Bang.\\n*   **Exoplanet Atmosphere Detections:** JWST has detected a variety of molecules in exoplanet atmospheres, including water, methane, carbon dioxide, and even potential biosignatures.\\n*   **Gravitational Wave Astronomy:** The detection of gravitational waves from merging black holes and neutron stars continues', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' to provide new insights into these objects and the processes that drive their mergers.\\n*   **Black Hole Imaging:** The Event Horizon Telescope (EHT) has captured images of the shadow of the supermassive black hole at the center of our galaxy, Sagittarius A*, and the black hole in the galaxy M87.\\n\\n**', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='IV. Challenges & Future Directions:**\\n\\n*   **Understanding Dark Matter & Dark Energy:** Determining the nature of dark matter and dark energy remains one of the biggest challenges in cosmology.\\n*   **Finding Life Beyond Earth:** The search for extraterrestrial life is a major goal of astronomy.\\n*   **Developing New Technologies:** Astronomy', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=\" is constantly pushing the boundaries of technology.\\n*   **Addressing Ethical Considerations:** As astronomy becomes more powerful, it's important to consider the ethical implications of our research, such as the impact of space debris on future missions.\\n*   **Promoting Diversity & Inclusion:** Astronomy needs to be more diverse and inclusive to attract\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' the best talent and ensure that everyone has the opportunity to contribute to the field.\\n\\n**V. How to Stay Informed:**\\n\\n*   **Read Popular Science Articles:** Magazines like *Sky & Telescope*, *Astronomy*, and websites like Space.com and NASA.gov.\\n*   **Follow Astronomers on', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' Social Media:** Many astronomers are active on Twitter and other social media platforms.\\n*   **Attend Public Lectures & Events:** Many universities and observatories offer public lectures and events on astronomy.\\n*   **Check Pre-print Servers:** arXiv.org hosts pre-prints of scientific papers.\\n*   **Read Scientific', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content=' Journals:** Journals like *The Astrophysical Journal*, *The Astronomical Journal*, and *Nature Astronomy* publish cutting-edge research in astronomy. (These are often behind paywalls, but university libraries often provide access).\\n\\nAstronomy is a truly exciting field, constantly pushing the boundaries of human knowledge and revealing the wonders of the universe', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0})}\n",
      "{'chunk': AIMessageChunk(content='. The next decade promises to be a golden age of discovery, with new telescopes and missions poised to revolutionize our understanding of the cosmos.\\n', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--5c9d3841-b947-41ae-845d-f067ff22a286', usage_metadata={'input_tokens': -33, 'input_token_details': {'cache_read': 0}, 'total_tokens': 2087, 'output_tokens': 2120})}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\" : {\"thread_id\" : \"3\"}}\n",
    "\n",
    "inputmessage = [HumanMessage(content=\"tell me alot about the Astronomy now\")]\n",
    "\n",
    "async for event in graph.astream_events( {\"messages\" : inputmessage}, config, version=\"v2\" ):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event[\"metadata\"].get(\"langgraph_node\", '') == \"convo_call_model\":\n",
    "        data = event[\"data\"]\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff65f2f-c1b0-4a55-bbd4-acb238867bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright|, let's dive into the San Francisco 49ers! Here'|s a breakdown of the team, covering their history, notable players, recent performance, and more|:\n",
      "\n",
      "**General Information:**\n",
      "\n",
      "*   **Team Name:** San Francisco 49ers (often shortened to \"Niners\" or \"49ers\")\n",
      "*|   **City:** Santa Clara, California (though they represent the San Francisco Bay Area)\n",
      "*   **Conference:** National Football Conference (NFC)\n",
      "*   **|Division:** NFC West\n",
      "*   **Founded:** 1946 (as part of the All-America Football Conference - AAFC)\n",
      "*   **Joined NFL:** 1950\n",
      "*   **Home Stadium:** Levi'|s Stadium (opened in 2014)\n",
      "*   **Team Colors:** Red, Gold, and White\n",
      "*   **Mascot:** Sourdough Sam\n",
      "\n",
      "**History and Legacy:**\n",
      "\n",
      "*   **Early Years| (AAFC and Early NFL):** The 49ers were initially a successful team in the AAFC before joining the NFL. They had some talented players but didn't achieve major success in their early NFL years.\n",
      "*   **The Bill Walsh Era (1979-1988):** This is| arguably the most iconic period in 49ers history. Head Coach Bill Walsh implemented the \"West Coast Offense,\" a revolutionary passing scheme emphasizing short, precise routes and timing.\n",
      "    *   **Joe Montana:** Quarterback Joe Montana became the face of the franchise and one of the greatest quarterbacks of all time under| Walsh's tutelage.\n",
      "    *   **Super Bowl Wins:** The 49ers won four Super Bowls during this era (XVI, XIX, XXIII, XXIV).\n",
      "    *   **Other Key Players:** Wide receiver Dwight Clark (of \"The Catch\" fame), running back Roger Craig, and receiver| Jerry Rice (who arrived later but became the greatest receiver ever) were crucial to their success.\n",
      "*   **The Steve Young Era (1991-1999):** After Montana's departure, Steve Young stepped in and continued the 49ers' winning tradition.\n",
      "    *   **Super Bowl| XXIX:** Young led the 49ers to another Super Bowl victory in 1995, throwing a record-breaking six touchdown passes.\n",
      "    *   **Continued Dominance:** The 49ers remained a consistent playoff contender throughout the 1990s.\n",
      "*   **Post|-Young Era:** The 49ers experienced a period of struggles and rebuilding after Young's retirement.\n",
      "*   **Jim Harbaugh Era (2011-2014):** Harbaugh brought the 49ers back to prominence, leading them to three consecutive NFC Championship games and a Super Bowl appearance| (XLVII), which they lost to the Baltimore Ravens.\n",
      "*   **Kyle Shanahan Era (2017-Present):** Shanahan, known for his offensive play-calling, has revitalized the 49ers.\n",
      "    *   **Super Bowl LIV:** He led the team to Super| Bowl LIV in 2020, where they lost to the Kansas City Chiefs.\n",
      "    *   **Recent Success:** The 49ers have remained a strong contender in the NFC, reaching the NFC Championship game multiple times.\n",
      "    *   **Super Bowl LVIII:** The 49ers played| in Super Bowl LVIII in 2024, losing to the Kansas City Chiefs in overtime.\n",
      "\n",
      "**Key Players (Past and Present):**\n",
      "\n",
      "*   **Joe Montana (QB):** Arguably the greatest quarterback in NFL history. Known for his poise, accuracy, and Super Bowl success.\n",
      "*   |**Jerry Rice (WR):** Widely considered the greatest wide receiver of all time. Holds numerous NFL records.\n",
      "*   **Steve Young (QB):** A highly talented and mobile quarterback who succeeded Montana and led the 49ers to another Super Bowl.\n",
      "*   **Ronnie Lott (S):** A| hard-hitting and intimidating safety who was a key part of the 49ers' dominant defense in the 1980s.\n",
      "*   **Dwight Clark (WR):** Best known for \"The Catch,\" a game-winning touchdown reception in the 1981 NFC Championship game.\n",
      "|*   **George Kittle (TE):** A current star tight end known for his blocking and receiving abilities.\n",
      "*   **Nick Bosa (DE):** A dominant defensive end and pass rusher.\n",
      "*   **Christian McCaffrey (RB):** A versatile running back acquired in 20|22, known for his rushing and receiving skills.\n",
      "*   **Brock Purdy (QB):** The current starting quarterback, drafted last overall in 2022, who has led the team to success.\n",
      "\n",
      "**Championships:**\n",
      "\n",
      "*   **Super Bowl Championships:** 5 (XVI, XIX|, XXIII, XXIV, XXIX)\n",
      "*   **NFC Championships:** 8\n",
      "*   **Division Championships:** 21\n",
      "\n",
      "**Current State of the Team:**\n",
      "\n",
      "*   The 49ers are consistently a Super Bowl contender under Kyle Shanahan.\n",
      "*   They have a strong roster with| talent on both offense and defense.\n",
      "*   The team is well-coached and has a clear identity.\n",
      "*   They are a major force in the NFC West.\n",
      "\n",
      "**Things to Know:**\n",
      "\n",
      "*   **\"The Catch\":** Dwight Clark's game-winning catch against the Dallas Cowboys in the |1981 NFC Championship game is one of the most iconic plays in NFL history.\n",
      "*   **The West Coast Offense:** Bill Walsh's offensive system revolutionized the NFL and became a model for many other teams.\n",
      "*   **Levi's Stadium:** The 49ers' current home stadium is located| in Santa Clara, about 45 miles south of San Francisco.\n",
      "*   **Faithful to The Bay:** The 49ers have a large and passionate fanbase throughout the San Francisco Bay Area.\n",
      "\n",
      "In summary, the San Francisco 49ers are a storied franchise with a rich history of success.| They have been home to some of the greatest players in NFL history and have consistently been a contender for championships. They are currently one of the top teams in the league and are poised to continue their winning tradition.\n",
      "|"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "\n",
    "async for event in graph.astream_events( {\"messages\": [input_message] }, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == \"convo_call_model\":\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8773c-b2a4-4fa3-a1b9-e7b12a825917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "-  API: http://127.0.0.1:2024\n",
    "-  Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "-  API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1f076da7-e7c6-6109-96cc-403735dae776', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5d329d02-84ee-4d99-a62a-0022ea72f999', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5d329d02-84ee-4d99-a62a-0022ea72f999', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3.0, \"a\": 2.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run--0bb75dbd-570f-4de6-bf24-31014b122f58-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'b': 3.0, 'a': 2.0}, 'id': '14e3d1be-2a1f-489c-a326-6a0b32b13aeb', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 63, 'output_tokens': 5, 'total_tokens': 68, 'input_token_details': {'cache_read': 0}}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5d329d02-84ee-4d99-a62a-0022ea72f999', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3.0, \"a\": 2.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run--0bb75dbd-570f-4de6-bf24-31014b122f58-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'b': 3.0, 'a': 2.0}, 'id': '14e3d1be-2a1f-489c-a326-6a0b32b13aeb', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 63, 'output_tokens': 5, 'total_tokens': 68, 'input_token_details': {'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '6a8dea7d-8ce6-43de-b504-e5965d2e86b6', 'tool_call_id': '14e3d1be-2a1f-489c-a326-6a0b32b13aeb', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='', data=None)\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5d329d02-84ee-4d99-a62a-0022ea72f999', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3.0, \"a\": 2.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run--0bb75dbd-570f-4de6-bf24-31014b122f58-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'b': 3.0, 'a': 2.0}, 'id': '14e3d1be-2a1f-489c-a326-6a0b32b13aeb', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 63, 'output_tokens': 5, 'total_tokens': 68, 'input_token_details': {'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '6a8dea7d-8ce6-43de-b504-e5965d2e86b6', 'tool_call_id': '14e3d1be-2a1f-489c-a326-6a0b32b13aeb', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run--364cf57c-6fad-494d-95e9-0a87d85345aa-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 71, 'output_tokens': 14, 'total_tokens': 85, 'input_token_details': {'cache_read': 0}}}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='b144f5ca-5afb-41ae-b509-70e1103b728f'\n",
      "=========================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 63, 'output_tokens': 5, 'total_tokens': 68, 'input_token_details': {'cache_read': 0}}, 'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3.0, \"a\": 2.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--3f93c274-a0fc-4957-a0be-9576120eed62-0' tool_calls=[{'name': 'multiply', 'args': {'b': 3.0, 'a': 2.0}, 'id': '5e53c26d-21a4-44ef-9dcb-70bf657ff650', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='6e4b1c63-5503-400f-9aae-144df3d02d33' tool_call_id='5e53c26d-21a4-44ef-9dcb-70bf657ff650'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 71, 'output_tokens': 14, 'total_tokens': 85, 'input_token_details': {'cache_read': 0}}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--8ee7852b-0389-47c1-850a-2b2e13c743bd-0'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "thread = await client.threads.create()\n",
    "\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages', None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c1057-580a-4a48-b276-7c955afa5ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "\n",
    "input_message = [HumanMessage(content=\"Multiply 2 and 3\")]\n",
    "\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\":input_message}, stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = await client.threads.create()\n",
    "\n",
    "input_message = [HumanMessage(content=\"Multiply 2 and 3\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4bcb419-2afa-4be5-bd2e-caa1a9a11a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "        Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\"\"\"\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        \n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\")\n",
    "        \n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    \n",
    "    return \"No tool calls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1f076e94-8066-6069-84e9-d7b00b150a6c\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: 4a2d5c63-15ab-42b8-a4e7-81b1608a9fd2, Function: multiply, Arguments: {'b': 3.0, 'a': 2.0}\n",
      "Response Metadata: Finish Reason - STOP\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "\n",
      "Response Metadata: Finish Reason - STOP\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\":input_message}, stream_mode=\"messages\"):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                \n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                \n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                \n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2cc5d-4aca-42f8-9bf0-bfd20cc9e8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
